{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c60c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "import neat\n",
    "\n",
    "DATA_PATH = \"salesdaily-data.xlsx\"\n",
    "CONFIG_PATH = \"NEAT.txt\"\n",
    "\n",
    "TARGET_COL = \"M01AE\"\n",
    "L = 2\n",
    "H = 1\n",
    "\n",
    "TRAIN_START, TRAIN_END = \"2014-01-02\", \"2019-06-30\"\n",
    "TEST_START,  TEST_END  = \"2019-07-01\", \"2019-10-08\"\n",
    "\n",
    "N_GENERATIONS = 100\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "BATCH_FRACTION = 0.35    \n",
    "L2_PENALTY = 1e-4        \n",
    "EPS = 1e-8\n",
    "\n",
    "df = pd.read_excel(DATA_PATH)\n",
    "df[\"datetime\"] = pd.to_datetime(df[\"datetime\"])\n",
    "df = df.sort_values(\"datetime\").reset_index(drop=True)\n",
    "\n",
    "df = df[[\"datetime\", TARGET_COL]].copy()\n",
    "\n",
    "df[\"month\"] = df[\"datetime\"].dt.month.astype(float)      # 1..12\n",
    "df[\"dow\"]   = df[\"datetime\"].dt.dayofweek.astype(float)  # 0..6\n",
    "\n",
    "df[\"lag1\"] = df[TARGET_COL].shift(1)\n",
    "df[\"lag2\"] = df[TARGET_COL].shift(2)\n",
    "df[\"y\"]    = df[TARGET_COL].astype(float)\n",
    "\n",
    "df = df.dropna(subset=[\"lag1\", \"lag2\", \"y\"]).reset_index(drop=True)\n",
    "\n",
    "train_mask = (df[\"datetime\"] >= pd.to_datetime(TRAIN_START)) & (df[\"datetime\"] <= pd.to_datetime(TRAIN_END))\n",
    "test_mask  = (df[\"datetime\"] >= pd.to_datetime(TEST_START))  & (df[\"datetime\"] <= pd.to_datetime(TEST_END))\n",
    "\n",
    "train_df = df.loc[train_mask].copy()\n",
    "test_df  = df.loc[test_mask].copy()\n",
    "\n",
    "# -----------------------------\n",
    "# Scale using TRAIN only\n",
    "# -----------------------------\n",
    "def scale_month(m): return (m - 1.0) / 11.0\n",
    "def scale_dow(d):   return d / 6.0\n",
    "\n",
    "train_df[\"month_s\"] = scale_month(train_df[\"month\"])\n",
    "train_df[\"dow_s\"]   = scale_dow(train_df[\"dow\"])\n",
    "test_df[\"month_s\"]  = scale_month(test_df[\"month\"])\n",
    "test_df[\"dow_s\"]    = scale_dow(test_df[\"dow\"])\n",
    "\n",
    "y_mean = train_df[\"y\"].mean()\n",
    "y_std  = train_df[\"y\"].std() + 1e-8\n",
    "\n",
    "for col in [\"y\", \"lag1\", \"lag2\"]:\n",
    "    train_df[col + \"_s\"] = (train_df[col] - y_mean) / y_std\n",
    "    test_df[col + \"_s\"]  = (test_df[col]  - y_mean) / y_std\n",
    "\n",
    "FEATURE_COLS = [\"month_s\", \"dow_s\", \"lag1_s\", \"lag2_s\"]\n",
    "TARGET_SCALED = \"y_s\"\n",
    "\n",
    "X_train = train_df[FEATURE_COLS].to_numpy(dtype=float)\n",
    "y_train = train_df[TARGET_SCALED].to_numpy(dtype=float)\n",
    "\n",
    "# Naive baseline (scaled): predict y(t) ≈ lag1_s\n",
    "naive_train = train_df[\"lag1_s\"].to_numpy(dtype=float)\n",
    "\n",
    "X_test   = test_df[FEATURE_COLS].to_numpy(dtype=float)\n",
    "y_test   = test_df[\"y\"].to_numpy(dtype=float)  # unscaled actual\n",
    "test_dates = test_df[\"datetime\"].to_numpy()\n",
    "\n",
    "# For evaluating baseline on test too (optional diagnostic)\n",
    "naive_test_unscaled = test_df[\"lag1\"].to_numpy(dtype=float)\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# NEAT: baseline-relative fitness\n",
    "# -----------------------------\n",
    "rng = np.random.default_rng(RANDOM_SEED)\n",
    "\n",
    "def eval_genomes(genomes, config):\n",
    "    \"\"\"\n",
    "    Fitness encourages beating the naive baseline (lag1 predictor).\n",
    "\n",
    "    Define:\n",
    "      mse_g     = MSE(genome_pred, y_true) on a batch\n",
    "      mse_naive = MSE(lag1, y_true) on same batch\n",
    "\n",
    "    Fitness:\n",
    "      improvement = 1 - (mse_g / (mse_naive + eps))\n",
    "    - If genome matches baseline => ~0\n",
    "    - Better than baseline => positive\n",
    "    - Worse than baseline => negative\n",
    "\n",
    "    Also add tiny L2 penalty on output magnitude for stability.\n",
    "    \"\"\"\n",
    "    n = len(y_train)\n",
    "    batch_size = max(256, int(BATCH_FRACTION * n))\n",
    "    idx = rng.choice(n, size=batch_size, replace=False)\n",
    "\n",
    "    Xb = X_train[idx]\n",
    "    yb = y_train[idx]\n",
    "    nb = naive_train[idx]\n",
    "\n",
    "    mse_naive = np.mean((nb - yb) ** 2) + EPS\n",
    "\n",
    "    for _, genome in genomes:\n",
    "        net = neat.nn.FeedForwardNetwork.create(genome, config)\n",
    "\n",
    "        preds = np.empty(batch_size, dtype=float)\n",
    "        for i, x in enumerate(Xb):\n",
    "            preds[i] = net.activate(x)[0]\n",
    "\n",
    "        mse_g = np.mean((preds - yb) ** 2)\n",
    "\n",
    "        # baseline-relative improvement\n",
    "        improvement = 1.0 - (mse_g / mse_naive)\n",
    "\n",
    "        # tiny stability penalty (discourages extreme outputs)\n",
    "        penalty = L2_PENALTY * float(np.mean(preds ** 2))\n",
    "\n",
    "        genome.fitness = float(improvement - penalty)\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Run evolution (progress bar over generations)\n",
    "# -----------------------------\n",
    "def run_neat():\n",
    "    config = neat.Config(\n",
    "        neat.DefaultGenome,\n",
    "        neat.DefaultReproduction,\n",
    "        neat.DefaultSpeciesSet,\n",
    "        neat.DefaultStagnation,\n",
    "        str(CONFIG_PATH),\n",
    "    )\n",
    "\n",
    "    p = neat.Population(config)\n",
    "    p.add_reporter(neat.StdOutReporter(False))\n",
    "    stats = neat.StatisticsReporter()\n",
    "    p.add_reporter(stats)\n",
    "\n",
    "    winner = None\n",
    "    for _ in tqdm(range(N_GENERATIONS), desc=\"NEAT evolution (generations)\"):\n",
    "        winner = p.run(eval_genomes, 1)\n",
    "\n",
    "    return winner, config\n",
    "\n",
    "\n",
    "winner, config = run_neat()\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Predict on TEST (progress bar)\n",
    "# -----------------------------\n",
    "winner_net = neat.nn.FeedForwardNetwork.create(winner, config)\n",
    "\n",
    "pred_test_s = np.empty(len(X_test), dtype=float)\n",
    "for i, x in enumerate(tqdm(X_test, desc=\"Predicting on test\")):\n",
    "    pred_test_s[i] = winner_net.activate(x)[0]\n",
    "\n",
    "pred_test = pred_test_s * y_std + y_mean  # unscale\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Plot: Actual vs Predicted on test (plus naive baseline)\n",
    "# -----------------------------\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(test_dates, y_test, label=\"Actual\")\n",
    "plt.plot(test_dates, pred_test, label=\"NEAT Predicted\")\n",
    "plt.plot(test_dates, naive_test_unscaled, label=\"Naive (lag1)\", alpha=0.7)\n",
    "plt.title(f\"NEAT Forecast — {TARGET_COL} (L=2, H=1) Test\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Sales\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "toxicity",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
